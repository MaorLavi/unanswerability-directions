{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27183444",
   "metadata": {},
   "source": [
    "### generate candidate directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f159295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose dataset: \"squad\", \"repliqa\", \"nq\", \"musique\"\n",
    "data_name = \"squad\"\n",
    "\n",
    "# Choose model: \"llama3\", \"gemma3\"\n",
    "model_name = \"llama3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f76fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.generate_directions import generate_directions\n",
    "from pipeline.model_utils.model_factory import construct_model_base\n",
    "from data.load_datasets import load_data\n",
    "\n",
    "path = f'data/abstain_aware_prompt/{data_name}'\n",
    "model_path = {\n",
    "    \"llama3\": \"meta-llama/meta-llama-3-8b-instruct\",\n",
    "    \"gemma3\": \"google/gemma-3-12b-it\"\n",
    "}[model_name]\n",
    "\n",
    "model_base = construct_model_base(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c50401",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_train, unans_train = load_data(path, \"train\")\n",
    "ans_val, unans_val = load_data(path, \"val\")\n",
    "dirs_path = f'pipeline/runs/{model_name}/{data_name}'\n",
    "candidate_directions = generate_directions(model_base, unans_train, ans_train, dirs_path, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59974147",
   "metadata": {},
   "source": [
    "### select unanswerability direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d0dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.select_by_steering import select_direction\n",
    "\n",
    "ans_val, unans_val = load_data(path, \"val\")  \n",
    "pos, layer, best_dir = select_direction(model_base, unans_val, ans_val, candidate_directions, f'{dirs_path}/select_by_steering', batch_size=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92eb970",
   "metadata": {},
   "source": [
    "### find threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63953c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.utils.threshold_utils import get_threshold_by_curve\n",
    "import json\n",
    "\n",
    "with open(f'{dirs_path}/select_by_steering/direction_metadata.json', 'r') as f:\n",
    "    dir_metadata = json.load(f)\n",
    "\n",
    "dir_vector = candidate_directions[pos, layer]\n",
    "fpr, tpr, roc_auc, best_roc_idx, threshold = get_threshold_by_curve(dir_vector, model_base, pos, layer, ans_val, unans_val)\n",
    "print(f\"threshold for {data_name} is {threshold:.2f}\")\n",
    "dir_metadata['threshold'] = f\"{threshold:.2f}\"\n",
    "with open(f'{dirs_path}/select_by_steering/direction_metadata.json', 'w') as f:\n",
    "    json.dump(dir_metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea20e0c",
   "metadata": {},
   "source": [
    "### classify unanswerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluate_by_projecting\n",
    "\n",
    "eval_data = \"musique\" # Choose eval dataset: \"squad\", \"repliqa\", \"nq\", \"musique\"\n",
    "eval_path = f'data/abstain_aware_prompt/{eval_data}'\n",
    "ans_test, unans_test = load_data(eval_path, \"test\")\n",
    "\n",
    "evaluate_by_projecting(f'{dirs_path}/evaluations/eval_on_{eval_data}', ans_test, unans_test, model_base, dir_vector, pos, layer, threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba2505",
   "metadata": {},
   "source": [
    "### threshold calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b38dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_val, unans_val = load_data(eval_path, \"val\")\n",
    "\n",
    "with open(f'{dirs_path}/select_by_steering/direction_metadata.json', 'r') as f:\n",
    "    dir_metadata = json.load(f)\n",
    "dir_vector = candidate_directions[pos, layer]\n",
    "fpr, tpr, roc_auc, best_roc_idx, threshold = get_threshold_by_curve(dir_vector, model_base, pos, layer, ans_val, unans_val)\n",
    "print(f\"threshold for {eval_data} is {threshold:.2f}\")\n",
    "dir_metadata[f'threshold_on_{eval_data}'] = f\"{threshold:.2f}\"\n",
    "with open(f'{dirs_path}/select_by_steering/direction_metadata.json', 'w') as f:\n",
    "    json.dump(dir_metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f528ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_by_projecting(f'{dirs_path}/evaluations/calibrated_threshold/eval_on_{eval_data}', ans_test, unans_test, model_base, dir_vector, pos, layer, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d2aab",
   "metadata": {},
   "source": [
    "## figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e398d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "datasets = [\"SQuAD\", \"RepLiQA\", \"NQ\", \"MuSiQue\"]\n",
    "dataset_order = datasets\n",
    "model_names = [\"llama3\", \"gemma3\"]\n",
    "methods = [\"Direction\", \"DirectionRefined\"]\n",
    "\n",
    "formal_names = {\"llama3\": \"Llama 3\", \"gemma3\": \"Gemma 3\"}\n",
    "method_titles = {\n",
    "    \"Direction\": \"Direction\",\n",
    "    \"DirectionRefined\": \"Direction (Calibrated Threshold)\"\n",
    "}\n",
    "\n",
    "method_x_positions = [0.25, 0.72]\n",
    "\n",
    "all_results = {\"F1\": {}, \"Recall\": {}}\n",
    "\n",
    "for model_name in model_names:\n",
    "    root = f\"pipeline/runs/{model_name}\"\n",
    "    for method in methods:\n",
    "        rows = []\n",
    "        for train_ds in datasets:\n",
    "            for eval_ds in datasets:\n",
    "                if method == \"Direction\":\n",
    "                    path = os.path.join(\n",
    "                        root, train_ds.lower(),\n",
    "                        f\"evaluations/eval_on_{eval_ds.lower()}/evaluation_results.json\"\n",
    "                    )\n",
    "                else:\n",
    "                    path = os.path.join(\n",
    "                        root, train_ds.lower(),\n",
    "                        f\"evaluations/calibrated_threshold/eval_on_{eval_ds.lower()}/evaluation_results.json\"\n",
    "                    )\n",
    "\n",
    "                if not os.path.exists(path):\n",
    "                    continue\n",
    "\n",
    "                with open(path, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                try:\n",
    "                    f1 = data[\"overall\"][\"f1\"] * 100\n",
    "                    recall = data[\"unanswerable\"][\"recall\"] * 100\n",
    "                except (KeyError, TypeError):\n",
    "                    continue\n",
    "\n",
    "                rows.append({\n",
    "                    \"Train Dataset\": train_ds,\n",
    "                    \"Eval Dataset\": eval_ds,\n",
    "                    \"F1\": f1,\n",
    "                    \"Recall\": recall,\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "        for metric in [\"F1\", \"Recall\"]:\n",
    "            pivot = (\n",
    "                df.pivot(index=\"Train Dataset\", columns=\"Eval Dataset\", values=metric)\n",
    "                  .reindex(index=dataset_order, columns=dataset_order)\n",
    "            )\n",
    "            all_results[metric][(model_name, method)] = pivot\n",
    "\n",
    "def plot_metric_grid(metric_name: str, save_suffix: str):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8.5), sharex=True, sharey=True)\n",
    "\n",
    "    for j, method in enumerate(methods):\n",
    "        fig.text(method_x_positions[j], 0.94, method_titles[method], fontsize=18, ha='center')\n",
    "\n",
    "    for i, model_name in enumerate(model_names):\n",
    "        for j, method in enumerate(methods):\n",
    "            ax = axes[i][j]\n",
    "            df_plot = all_results[metric_name].get((model_name, method))\n",
    "            if df_plot is not None:\n",
    "                sns.heatmap(\n",
    "                    df_plot,\n",
    "                    annot=True,\n",
    "                    fmt=\".1f\",\n",
    "                    cmap=\"Blues\",\n",
    "                    vmin=0, vmax=100,\n",
    "                    ax=ax,\n",
    "                    annot_kws={\"size\": 13}\n",
    "                )\n",
    "\n",
    "            ax.set_title(formal_names[model_name], fontsize=16)\n",
    "\n",
    "            if j == 0:\n",
    "                ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)\n",
    "            if i == 1:\n",
    "                ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "\n",
    "    for ax in axes[1]:\n",
    "        ax.set_xlabel(\"Evaluation Dataset\", fontsize=16, labelpad=10)\n",
    "    for ax in axes[:, 0]:\n",
    "        ax.set_ylabel(\"Training Dataset\", fontsize=16, labelpad=10)\n",
    "    for ax in axes[:, 1]:\n",
    "        ax.set_ylabel(\"\")\n",
    "    for ax in axes[0]:\n",
    "        ax.set_xlabel(\"\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    plt.savefig(f\"plots/methods_by_model_heatmaps_{save_suffix}.png\", bbox_inches='tight', dpi=300)\n",
    "    plt.savefig(f\"plots/methods_by_model_heatmaps_{save_suffix}.pdf\", format='pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6792a3",
   "metadata": {},
   "source": [
    "### Unanswerable prompts recall heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_grid(\"Recall\", \"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec13bf",
   "metadata": {},
   "source": [
    "### F1 scores heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a535968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_grid(\"F1\", \"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539b807",
   "metadata": {},
   "source": [
    "### ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea04bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pipeline.utils.threshold_utils import get_threshold_by_curve\n",
    "from pipeline.model_utils.model_factory import construct_model_base\n",
    "from data.load_datasets import load_data\n",
    "import json\n",
    "\n",
    "def plot_roc(ax, curves, model_label):\n",
    "    sns.set(style=\"whitegrid\", rc={\"lines.linewidth\": 2})\n",
    "    #sns.set_palette(sns.color_palette(\"Paired\"))\n",
    "    custom_palette = [\"#7a6bbf\", \"#ff9c42\", \"#5cb85c\", \"#e15759\"]\n",
    "    sns.set_palette(custom_palette)\n",
    "\n",
    "    \n",
    "    for name, d in curves.items():\n",
    "        sns.lineplot(x=d[\"fpr\"], y=d[\"tpr\"], label=f\"{name} (AUC = {d['auc']:.2f})\", ax=ax)\n",
    "        ax.scatter(d[\"fpr\"][d[\"idx\"]], d[\"tpr\"][d[\"idx\"]],\n",
    "                   s=60, marker='o', edgecolors='black',\n",
    "                   label=f\"{name} threshold = {d['thr']:.2f}\")\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='gray', linewidth=1)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=18)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=18)\n",
    "    ax.set_title(f'{model_label}', fontsize=20)\n",
    "    ax.legend(loc='lower right', frameon=True, fontsize=14)\n",
    "    ax.grid(True, linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Load and plot\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(7, 10))\n",
    "\n",
    "with open(\"pipeline/runs/llama3/roc_curves_data.json\", \"r\") as f:\n",
    "    llama_curves = json.load(f)\n",
    "with open(\"pipeline/runs/gemma3/roc_curves_data.json\", \"r\") as f:\n",
    "    gemma_curves = json.load(f)\n",
    "\n",
    "plot_roc(axs[0], llama_curves, \"Llama 3\")\n",
    "plot_roc(axs[1], gemma_curves, \"Gemma 3\")\n",
    "axs[0].set_xlabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/roc_curves.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
