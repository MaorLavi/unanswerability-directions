{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6188e0b1",
   "metadata": {},
   "source": [
    "### steering effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca94fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import generate_and_save_completions_for_dataset\n",
    "from pipeline.model_utils.model_factory import construct_model_base\n",
    "from data.load_datasets import load_data\n",
    "from pipeline.utils.hook_utils import get_activation_addition_input_pre_hook\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "datasets = [\"squad\", \"repliqa\", \"nq\", \"musique\"]\n",
    "alphas = np.arange(-2.0, 2.0 + 0.25, 0.25)\n",
    "\n",
    "all_rows = []\n",
    "for model_name in [\"llama3\", \"gemma3\"]:\n",
    "    for data_name in datasets:\n",
    "        print(f\"Running on dataset: {data_name}\")\n",
    "        path = f'data/abstain_aware_prompt/{data_name}'\n",
    "        ans_val, unans_val = load_data(path, \"val\")\n",
    "\n",
    "        model_path = {\n",
    "            \"llama3\": \"meta-llama/meta-llama-3-8b-instruct\",\n",
    "            \"gemma3\": \"google/gemma-3-12b-it\"\n",
    "            }[model_name]\n",
    "        model_base = construct_model_base(model_path) \n",
    "        with open(f'pipeline/runs/{model_name}/{data_name}/select_by_steering/direction_metadata.json', 'r') as f:\n",
    "            direction_metadata = json.load(f)\n",
    "        pos = direction_metadata['pos']\n",
    "        layer = direction_metadata['layer']\n",
    "\n",
    "        dirs_path = f'pipeline/runs/{model_name}/{data_name}'\n",
    "        candidate_directions = torch.load(f'{dirs_path}/mean_diffs.pt')\n",
    "        dir_vector = candidate_directions[pos, layer]\n",
    "\n",
    "        for alpha in alphas:\n",
    "            fwd_pre_hooks = [(model_base.model_block_modules[layer], get_activation_addition_input_pre_hook(vector=dir_vector, coeff=alpha))]\n",
    "            fwd_hooks = []\n",
    "\n",
    "            ans_completions = generate_and_save_completions_for_dataset(model_base, fwd_pre_hooks, fwd_hooks, ans_val)\n",
    "            unans_completions = generate_and_save_completions_for_dataset(model_base, fwd_pre_hooks, fwd_hooks, unans_val)\n",
    "\n",
    "            all_rows.append({\"model_name\": model_name, \"alpha\": alpha, \"ans_completions\": ans_completions, \"prompt_type\": \"Answerable\", \"dataset\": data_name.capitalize()})\n",
    "            all_rows.append({\"model_name\": model_name, \"alpha\": alpha, \"unans_completions\": unans_completions, \"prompt_type\": \"Unanswerable\", \"dataset\": data_name.capitalize()})\n",
    "\n",
    "with open(f'analysis/causal_interventions/completions_under_interventions.json', 'w') as f:\n",
    "    json.dump(all_rows, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a762ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# run eval_causal_interventions.py to save abstention rates by alpha\n",
    "\n",
    "with open('analysis/causal_interventions/abstention_rates_by_alpha.json', 'r') as f:\n",
    "    all_rows = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "df[\"dataset\"] = df[\"dataset\"].replace({\n",
    "    \"Squad\": \"SQuAD\",\n",
    "    \"Repliqa\": \"RepliQA\",\n",
    "    \"Nq\": \"NQ\",\n",
    "    \"Musique\": \"MuSiQue\"\n",
    "})\n",
    "df[\"model\"] = df[\"model\"].replace({\n",
    "    \"llama3\": \"Llama 3\",\n",
    "    \"gemma3\": \"Gemma 3\"\n",
    "})\n",
    "\n",
    "df[\"label\"] = df[\"model\"] + \" – \" + df[\"prompt_type\"]\n",
    "\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "lighter_colors = [\"#539ecd\", \"#ff9c42\", \"#5cb85c\", \"#e15759\"]\n",
    "\n",
    "custom_palette = [\"#7a6bbf\", \"#ff9c42\", \"#5cb85c\", \"#e15759\"]\n",
    "sns.set_palette(custom_palette)\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    df, \n",
    "    col=\"dataset\", \n",
    "    hue=\"label\", \n",
    "    col_wrap=2, \n",
    "    height=3.5,\n",
    "    aspect=1.2,\n",
    "    sharey=True,\n",
    "    margin_titles=False\n",
    ")\n",
    "\n",
    "g.map_dataframe(\n",
    "    sns.lineplot, \n",
    "    x=\"alpha\", \n",
    "    y=\"percentage\", \n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "for idx, ax in enumerate(g.axes.flat):\n",
    "    ax.axvline(0, linestyle=\"--\", color=\"gray\", linewidth=1)\n",
    "    ax.axvline(1, linestyle=\":\", color=\"black\", linewidth=1)\n",
    "    \n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    title = ax.get_title().replace(\"dataset = \", \"\")\n",
    "    ax.set_title(title, fontsize=22)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "\n",
    "\n",
    "handles, labels = g.axes[0].get_legend_handles_labels()\n",
    "g.fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    loc=\"lower center\",\n",
    "    ncol = 2,\n",
    "    bbox_to_anchor=(0.53, -0.21),\n",
    "    frameon=True,\n",
    "    fontsize=19,\n",
    "    title_fontsize=13\n",
    ")\n",
    "\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "\n",
    "g.tight_layout()\n",
    "\n",
    "g.fig.suptitle(\"Direction Scaling Effects Across Datasets\", fontsize=26, x=0.53, y=1.04)\n",
    "g.fig.text(0.53, -0.02, \"Direction Scale (α)\", ha='center', fontsize=24)\n",
    "g.fig.text(-0.01, 0.5, \"Abstention Rate (%)\", va='center', rotation='vertical', fontsize=24)\n",
    "g.savefig('plots/causal_interventions.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f206d34",
   "metadata": {},
   "source": [
    "### unanswerability score distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633263b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm import tqdm\n",
    "from evaluate import project_onto_dom, get_hidden_vector\n",
    "from data.load_datasets import load_data\n",
    "from pipeline.model_utils.model_factory import construct_model_base\n",
    "\n",
    "\n",
    "model_path=\"meta-llama/meta-llama-3-8b-instruct\"\n",
    "model_name = \"llama3\"\n",
    "model_base = construct_model_base(model_path)\n",
    "layer = 16\n",
    "pos = -1\n",
    "thresholds = {'squad': -0.4, 'nq': -0.24}\n",
    "dirs_to_run = ['squad', 'nq']\n",
    "palette = sns.color_palette(\"tab10\", 8)\n",
    "\n",
    "rep_ans_prompts, rep_unans_prompts = load_data('data/abstain_aware_prompt/repliqa', \"val\")\n",
    "squad_ans_prompts, squad_unans_prompts = load_data('data/abstain_aware_prompt/squad', \"val\")\n",
    "nq_ans_prompts, nq_unans_prompts = load_data('data/abstain_aware_prompt/nq', \"val\")\n",
    "musique_ans_prompts, musique_unans_prompts = load_data('data/abstain_aware_prompt/musique', \"val\")\n",
    "\n",
    "prompt_groups = [\n",
    "    ('RepLiQA Answerable', rep_ans_prompts, palette[0]),\n",
    "    ('RepLiQA Unanswerable', rep_unans_prompts, palette[1]),\n",
    "    ('SQuAD Answerable', squad_ans_prompts, palette[2]),\n",
    "    ('SQuAD Unanswerable', squad_unans_prompts, palette[3]),\n",
    "    ('NQ Answerable', nq_ans_prompts, palette[4]),\n",
    "    ('NQ Unanswerable', nq_unans_prompts, palette[5]),\n",
    "    ('MuSiQue Answerable', musique_ans_prompts, palette[6]),\n",
    "    ('MuSiQue Unanswerable', musique_unans_prompts, palette[7]),\n",
    "]\n",
    "\n",
    "all_scores = {}\n",
    "\n",
    "for dir_data in dirs_to_run:\n",
    "    dirs_path = f'pipeline/runs/{model_name}/{dir_data}'\n",
    "    candidate_directions = torch.load(f'{dirs_path}/mean_diffs.pt')\n",
    "    dir_vector = candidate_directions[pos, layer].to(dtype=torch.float32)\n",
    "    \n",
    "    all_scores[dir_data] = {}\n",
    "    \n",
    "    for label, prompts, _ in prompt_groups:\n",
    "        scores = [\n",
    "            project_onto_dom(get_hidden_vector(prompt, model_base, pos, layer), dir_vector).item()\n",
    "            for prompt in tqdm(prompts, desc=f\"Processing {label} with {dir_data} direction\")\n",
    "        ]\n",
    "        all_scores[dir_data][label] = scores\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(9, 14), sharex=True)\n",
    "\n",
    "for idx, dir_data in enumerate(dirs_to_run):\n",
    "    ax = axes[idx]\n",
    "    for i, (label, _, color) in enumerate(prompt_groups):\n",
    "        scores = all_scores[dir_data][label]\n",
    "        sns.histplot(\n",
    "            scores, color=color, label=label, kde=True, bins=30, alpha=0.2,\n",
    "            line_kws={'alpha': 1, 'linewidth': 2}, edgecolor=(0, 0, 0, 0.2), ax=ax\n",
    "        )\n",
    "\n",
    "    thresh = thresholds[dir_data]\n",
    "    ax.axvline(thresh, color='black', linestyle='dashed', label=f'Threshold = {thresh}')\n",
    "    ax.set_title(f\"Direction from {dir_data.upper()}\", fontsize=20)\n",
    "    ax.set_ylabel(\"Density\", fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax.set_xlabel(r\"$\\phi_{\\mathrm{unans}}$\", fontsize=16)\n",
    "\n",
    "custom_lines = [Line2D([0], [0], color=palette[i], lw=2) for i in range(8)]\n",
    "custom_lines.append(Line2D([0], [0], color='black', linestyle='dashed', lw=2))\n",
    "labels = [\n",
    "    'RepLiQA Answerable', 'RepLiQA Unanswerable',\n",
    "    'SQuAD Answerable', 'SQuAD Unanswerable',\n",
    "    'NQ Answerable', 'NQ Unanswerable',\n",
    "    'MuSiQue Answerable', 'MuSiQue Unanswerable',\n",
    "    'Threshold'\n",
    "]\n",
    "fig.legend(custom_lines, labels, fontsize=14, loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.01))\n",
    "\n",
    "plt.suptitle(\"Distributions of Unanswerability Scores\", fontsize=24, y=0.99)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.12)\n",
    "\n",
    "plt.savefig(f\"plots/{model_name}_unanswerability_scores.png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(f\"plots/{model_name}_unanswerability_scores.pdf\", format='pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275644ea",
   "metadata": {},
   "source": [
    "### combining directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import evaluate_by_projecting_2layers\n",
    "from pipeline.utils.threshold_utils import get_threshold_by_curve_2layers\n",
    "from pipeline.model_utils.model_factory import construct_model_base\n",
    "import json\n",
    "import torch\n",
    "from data.load_datasets import load_data\n",
    "\n",
    "model_path=\"meta-llama/meta-llama-3-8b-instruct\"\n",
    "model_name = \"llama3\"\n",
    "model_base = construct_model_base(model_path)\n",
    "\n",
    "data_name = \"squad\" # choose direction data from ['squad', 'repliqa', 'nq', 'musique']\n",
    "dirs_path = f'pipeline/runs/{model_name}/{data_name}'\n",
    "with open(f'{dirs_path}/select_by_steering/direction_evaluations.json', 'r') as f:\n",
    "    direction_evaluations = json.load(f)\n",
    "pos1 = direction_evaluations[0]['position']\n",
    "layer1 = direction_evaluations[0]['layer']\n",
    "pos2 = direction_evaluations[1]['position']\n",
    "layer2 = direction_evaluations[1]['layer']\n",
    "\n",
    "candidate_directions = torch.load(f'{dirs_path}/mean_diffs.pt')\n",
    "dir_vector1 = candidate_directions[pos1, layer1]\n",
    "dir_vector2 = candidate_directions[pos2, layer2]\n",
    "\n",
    "eval_data = 'nq' # choose eval data from ['squad', 'repliqa', 'nq', 'musique']\n",
    "path = f'data/abstain_aware_prompt/{data_name}' #change to eval_data for threshold calibration \n",
    "ans_val, unans_val = load_data(path, \"val\")\n",
    "\n",
    "fpr, tpr, roc_auc, best_roc_idx, threshold = get_threshold_by_curve_2layers(dir_vector1, dir_vector2, model_base, pos1, pos2, layer1, layer2, ans_val, unans_val)\n",
    "\n",
    "ans_test, unans_test = load_data(f'data/abstain_aware_prompt/{eval_data}', \"test\")\n",
    "\n",
    "evaluate_by_projecting_2layers(f'{dirs_path}/evaluations/two_vectors/eval_on_{eval_data}', ans_test, unans_test, model_base, dir_vector1, dir_vector2, pos1, pos2, layer1, layer2, threshold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv-tova)",
   "language": "python",
   "name": "myenv-tova"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
